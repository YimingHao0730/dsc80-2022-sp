{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from IPython.display import HTML, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 15 – Requests and Parsing HTML\n",
    "\n",
    "## DSC 80, Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Project 3 is released, and is due on **Thursday, May 12th at 11:59PM**.\n",
    "    - See [dsc80.com/project3](https://dsc80.com/project3/) for all the details.\n",
    "- Midterm Exam grades are released! See [#935](https://campuswire.com/c/G325FA25B/feed/935) for details.\n",
    "- Lab 5 is due **today at 11:59PM**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- APIs and web scraping.\n",
    "- The anatomy of HTML documents.\n",
    "- Parsing HTML via Beautiful Soup.\n",
    "- Example: Scraping the HDSI Faculty page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## APIs and web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Programmatic requests\n",
    "\n",
    "* We learned how to use the Python `requests` package to exchange data via HTTP.\n",
    "    - `GET` requests are used to request data **from** a server.\n",
    "    - `POST` requests are used to **send** data to a server. \n",
    "* There are two ways of collecting data via requests:\n",
    "    * By using a published API (application programming interface).\n",
    "    * By scraping a webpage to collect its HTML source code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### APIs\n",
    "\n",
    "* An API is a service that makes data directly available to the user in a convenient fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Advantages:\n",
    "    - The data are usually clean, up-to-date, and ready to use.\n",
    "    - The presence of a API signals that the data provider is okay with you using their data.\n",
    "    - The data provider can plan and regulate data usage.\n",
    "        - Some APIs require you to create an API \"key\", which is like an account for using the API.\n",
    "        - APIs can also give you access to data that isn't publicly available on a webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Disadvantages:\n",
    "    - APIs don't always exist for the data you want!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### API terminology\n",
    "\n",
    "- A URL, or uniform resource locator, describes the location of a website or resource.\n",
    "\n",
    "- An **API endpoint** is a URL of the data source that the user wants to make requests to.\n",
    "\n",
    "- For example, on the [Reddit API](https://www.reddit.com/dev/api/):\n",
    "    * the `/comments` endpoint retrieves information about comments.\n",
    "    * the `/hot` endpoint retrieves data about posts labeled \"hot\" right now. \n",
    "    - To access these endpoints, you add the endpoint name to the base URL of the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### API requests\n",
    "\n",
    "- API requests are just `GET`/`POST` requests to a specially maintained URL.\n",
    "- Let's test out the [Pokémon API](https://pokeapi.co)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, let's make a `GET` request for `'squirtle'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://pokeapi.co/api/v2/pokemon/squirtle')\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the 200 status code is good! Let's take a look at the **content**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like JSON. We can extract the JSON from this request with the `json` method (or by passing `r.text` to `json.loads`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try a `GET` request for `'billy'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://pokeapi.co/api/v2/pokemon/billy')\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping\n",
    "\n",
    "* Scraping is the act of programmatically \"browsing\" the web, downloading the source code (HTML) of pages that you're interested in extracting data from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Advantages:\n",
    "    * You can always do it!\n",
    "        - e.g. Google scrapes webpages in order to make them searchable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Disadvantages:\n",
    "    - It is often difficult to parse and clean scraped data.\n",
    "        - Source code often includes a lot of content unrelated to the data you're trying to find (e.g. formatting, advertisements, other text).\n",
    "    - Websites can change often, so scraping code can get outdated quickly.\n",
    "    - Websites may not want you to scrape their data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In general, we prefer APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Accessing HTML\n",
    "\n",
    "Let's make a `GET` request to the HDSI Faculty page and see what the resulting HTML looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://datascience.ucsd.edu/about/faculty/faculty/'\n",
    "r = requests.get(url)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlText = r.text\n",
    "len(urlText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(urlText[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wow, that is gross looking! 😰 \n",
    "\n",
    "- It is **raw** HTML, which web browsers use to display websites.\n",
    "- The information we are looking for – faculty information – is in there somewhere, but we have to search for it and extract it, which we wouldn't have to do if we had an API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Best practices for scraping\n",
    "\n",
    "1. **Send requests slowly** and be upfront about what you are doing!\n",
    "2. Respect the policy published in the page's `robots.txt` file.\n",
    "    - Many sites have a `robots.txt` file in their root directory, which contains a policy that allows or disallows automatic access to their site. \n",
    "    - See [here](https://moz.com/learn/seo/robotstxt) or Lab 5, Question 5 for more details.\n",
    "3. Don't spoof your User-agent (i.e. don't try to trick the server into thinking you are a person).\n",
    "4. Read the Terms of Service for the site and follow it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consequences of irresponsible scraping\n",
    "\n",
    "If you make too many requests:\n",
    "* The server may block your IP Address.\n",
    "    - Everyone in your dorm might lose access to Google! (Seriously!)\n",
    "* You may take down the website.\n",
    "    - A journalist scraped and accidentally took down the Cook County Inmate Locater.\n",
    "    - As a result, inmate's families weren't able to contact them while the site was down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The anatomy of HTML documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is HTML?\n",
    "\n",
    "* HTML (HyperText Markup Language) is **the** basic building block of the internet. \n",
    "* It defines the content and layout of a webpage, and as such, it is what you get back when you scrape a webpage.\n",
    "* See [this tutorial](http://fab.academany.org/2018/labs/fablaboshanghai/students/bob-wu/Fabclass/week2_project_management/HTML.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!cat data/lec15_ex1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The anatomy of HTML documents\n",
    "\n",
    "* **HTML document**: The totality of markup that makes up a webpage.\n",
    "\n",
    "* **Document Object Model (DOM)**: The internal representation of a HTML document as a hierarchical **tree** structure.\n",
    "\n",
    "* **HTML element**: An object in the DOM, such as a paragraph, header, or title.\n",
    "* **HTML tags**: Markers that denote the **start** and **end** of an element, such as `<p>` and `</p>`.\n",
    "\n",
    "<center><img src='imgs/dom.jpg'></center>\n",
    "\n",
    "<center><a href='https://simplesnippets.tech/what-is-document-object-modeldom-how-js-interacts-with-dom/'>(source)</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Useful tags to know\n",
    "\n",
    "\n",
    "|Element|Description|\n",
    "|:---|:---|\n",
    "|`<html>`|the document|\n",
    "|`<head>`|the header|\n",
    "|`<body>`|the body|\n",
    "|`<div>` |a logical division of the document|\n",
    "|`<span>`|an *in-line* logical division|\n",
    "|`<p>`|a paragraph|\n",
    "| `<a>`| an anchor (hyper-link)|\n",
    "|`<h1>, <h2>, ...`| header(s) |\n",
    "|`<img>`| an image |\n",
    "\n",
    "There are many, many more. See [this article](https://en.wikipedia.org/wiki/HTML_element) for examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: images and hyperlinks\n",
    "\n",
    "Tags can have **attributes**, which further specify how to display information on a webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For instance, `<img>` tags have `src` and `alt` attributes (among others):\n",
    "\n",
    "```html\n",
    "<img src=\"billy-selfie.png\" alt=\"A photograph of Billy.\" width=500>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Hyperlinks have `href` attributes: \n",
    "\n",
    "```html\n",
    "Click <a href=\"https://dsc80.com/project3\">this link</a> to access Project 3.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What do you think this webpage looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/lec15_ex2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `<div>` tag\n",
    "\n",
    "```html\n",
    "<div style=\"background-color:lightblue\">\n",
    "  <h3>This is a heading</h3>\n",
    "  <p>This is a paragraph.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "* The `<div>` tag defines a division or a \"section\" of an HTML document.\n",
    "    * Think of a `<div>` as a \"cell\" in a Jupyter Notebook.\n",
    "\n",
    "* The `<div>` element is often used as a container for other HTML elements to style them with CSS or to perform operations involving them using JavaScript.\n",
    "\n",
    "* `<div>` elements often have attributes, which are important when scraping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Document trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/lec15_ex1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Under the document object model (DOM), HTML documents are trees. In DOM trees, child nodes are **ordered**.\n",
    "\n",
    "<center>\n",
    "\n",
    "<img src=\"imgs/webpage_anatomy.png\" width=\"50%\">\n",
    "\n",
    "</center>    \n",
    "\n",
    "What does the DOM tree look like for this document?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/dom_tree.png\" width=\"50%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Quote scraping\n",
    "\n",
    "Consider the following webpage.\n",
    "\n",
    "<center><img src=\"imgs/quotes2scrape.png\" width=60%></center>\n",
    "\n",
    "- What do you think the DOM tree looks like?\n",
    "- If you had to store the data on this page in a DataFrame, what would the rows and columns represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/quote_dom.png\" width=\"50%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parsing HTML via Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Beautiful Soup 🍜\n",
    "\n",
    "* [Beautiful Soup 4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) is a Python HTML parser.\n",
    "    - To \"parse\" means to \"extract meaning from a sequence of symbols\".\n",
    "* **Warning:** Beautiful Soup 4 and Beautiful Soup 3 work differently, so make sure you are using and looking at documentation for Beautiful Soup 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example HTML document\n",
    "\n",
    "To start, let's instantiate a `BeautifulSoup` object, using the source code for an HTML page with the DOM tree shown below:\n",
    "\n",
    "<center><img src=\"imgs/dom_tree_1.png\" width=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The string `html_string` contains an HTML \"document\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "html_string = '''\n",
    "<html>\n",
    "    <body>\n",
    "      <div id=\"content\">\n",
    "        <h1>Heading here</h1>\n",
    "        <p>My First paragraph</p>\n",
    "        <p>My <em>second</em> paragraph</p>\n",
    "        <hr>\n",
    "      </div>\n",
    "      <div id=\"nav\">\n",
    "        <ul>\n",
    "          <li>item 1</li>\n",
    "          <li>item 2</li>\n",
    "          <li>item 3</li>\n",
    "        </ul>\n",
    "      </div>\n",
    "    </body>\n",
    "</html>\n",
    "'''.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `HTML` function in the `IPython.display` module, we can render an HTML document from within our Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(html_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `BeautifulSoup` objects\n",
    "\n",
    "`bs4.BeautifulSoup` takes in a string or file-like object representing HTML (`markup`) and returns a **parsed** document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs4.BeautifulSoup?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, we pass the result of a `GET` request to `bs4.BeautifulSoup`, but here we will pass our hand-crafted `html_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(html_string)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BeautifulSoup` objects have several useful attributes, e.g. `text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Child nodes\n",
    "\n",
    "- Recall, HTML documents are represented as trees.\n",
    "    - Each page element becomes a node in this tree.\n",
    "- A `BeautifulSoup` object represents a **node** in the tree.\n",
    "    - Each `BeautifulSoup` object has 0 or more child nodes.\n",
    "    - To access the children of a node, use the `children` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: iterators\n",
    "\n",
    "On the previous slide, we saw that that `soup.children` isn't another `BeautifulSoup` object, but rather something of the form `<list_iterator at 0x7f7b0ab8c370>`.\n",
    "\n",
    "What are [iterators](https://www.w3schools.com/python/python_iterators.asp), again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [1, 2, 3, 4]\n",
    "double = map(lambda x: x ** 2, nums)\n",
    "double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Child nodes\n",
    "\n",
    "The `children` attribute returns an iterator so that it doesn't have to load the entire DOM tree in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(soup.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = next(soup.children)\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(root.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(root.children)[1].children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(list(root.children)[1].children)[3].children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Depth-first traversal through `descendants`\n",
    "\n",
    "- While we could use the `children` attribute to navigate to any node in a `BeautifulSoup` tree, there are easier ways of navigating the tree.\n",
    "\n",
    "- The `descendants` attribute traverses a `BeautifulSoup` tree using **depth-first traversal**.\n",
    "    - Why depth-first? Elements closer to one another on a page are more likely to be related than elements further away.\n",
    "    - Question: What type of depth-first traversal does this use – preorder, inorder, or postorder traversal?\n",
    "\n",
    "<center><img src=\"imgs/dom_tree_1.png\" width=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in soup.descendants:\n",
    "    # print(child) # What would happen if we ran this instead?\n",
    "    if isinstance(child, str):\n",
    "        continue\n",
    "    print(child.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding elements in a tree\n",
    "\n",
    "Practically speaking, you will not use the `children` or `descendants` attributes directly very often. Instead, you will use the following methods:\n",
    "\n",
    "- `soup.find(tag)`, which finds the **first** instance of a tag (the first one on the page, i.e. the first one that DFS sees).\n",
    "    - More general: `soup.find(name=None, attrs={}, recursive=True, text=None, **kwargs)`.\n",
    "- `soup.find_all(tag)` will find **all** instances of a tag.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `find`\n",
    "\n",
    "Let's try and extract the first `<div>` subtree.\n",
    "\n",
    "<center><img src=\"imgs/dom_tree_1.png\" width=\"60%\"></center>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = soup.find('div')\n",
    "div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"imgs/dom_subtree_1.png\" width=\"30%\"></center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and find the `<div>` element that has an `id` attribute equal to `'nav'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div', attrs={'id': 'nav'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find` will return the first occurrence of a tag, regardless of what depth it is in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('ul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('li')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `find_all`\n",
    "\n",
    "`find_all` returns a list of all matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.text for x in soup.find_all('li')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text` is a node attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Node attributes\n",
    "* The `text` attribute of a tag element gets the text between the opening and closing tags.\n",
    "* The `attrs` attribute lists all attributes of a tag.\n",
    "* The `get(key)` method gets the value of a tag attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div').attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div').get('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can access tags using attribute notation, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.html.div.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.html.div.h1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.html.div.next_sibling.next_sibling.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Scraping the HDSI Faculty page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "Let's try and extract a list of HDSI Faculty from https://datascience.ucsd.edu/about/faculty/faculty/.\n",
    "\n",
    "A good first step is to use the \"inspect element\" tool in our web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac_response = requests.get('https://datascience.ucsd.edu/about/faculty/faculty/')\n",
    "fac_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(fac_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It seems like the relevant `<div>`s for faculty are the ones where the `data-entry-type` attribute is equal to `'individual'`. Let's find all of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "divs = soup.find_all('div', attrs={'data-entry-type': 'individual'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within here, we need to extract each faculty member's name. It seems like names are stored in the `title` attribute within an `<a>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('a').get('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract job titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('h4').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And bios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('div', attrs={'class': 'cn-bio'}).text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's create a DataFrame consisting of names and bios for each faculty member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = [div.find('a').get('title') for div in divs]\n",
    "names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [div.find('h4').text if div.find('h4') else '' for div in divs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios = [div.find('div', attrs={'class': 'cn-bio'}).text.strip() for div in divs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty = pd.DataFrame().assign(name=names, title=titles, bio=bios)\n",
    "faculty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty[faculty['title'] == 'Lecturer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if we want to get faculty members' pictures? It seems like we should look at the attributes of an `<img>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_picture(name):\n",
    "    idx = names.index(name)\n",
    "    url = divs[idx].find('img').get('srcset')\n",
    "    url = 'https://' + url.strip('/').strip(' 1x')\n",
    "    display(Image(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_picture('Suraj Rampure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- APIs allow us to request information from web servers in a convenient fashion.\n",
    "- When APIs don't exist, we instead scrape webpages to access their source HTML and then parse the HTML to extract the information we care about.\n",
    "- Under the document object model (DOM), HTML documents are trees.\n",
    "    - Elements are defined by tags.\n",
    "- Beautiful Soup is an HTML parser that allows us to (somewhat) easily extract information from HTML documents.\n",
    "    - `soup.find` and `soup.find_all` are the functions you will use most often.\n",
    "- **Next time:** Another scraping example. Regular expressions."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
